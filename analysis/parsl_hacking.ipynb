{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import parsl\n",
    "import os\n",
    "from parsl.app.app import python_app, bash_app\n",
    "from parsl.configs.local_threads import config\n",
    "\n",
    "from parsl.providers import LocalProvider,CondorProvider\n",
    "from parsl.channels import LocalChannel,SSHChannel\n",
    "from parsl.config import Config\n",
    "from parsl.executors import HighThroughputExecutor\n",
    "\n",
    "from parsl.addresses import address_by_hostname\n",
    "\n",
    "x509_proxy = 'x509up_u%s'%(os.getuid())\n",
    "\n",
    "wrk_init = '''\n",
    "source /cvmfs/sft.cern.ch/lcg/views/LCG_95apython3/x86_64-centos7-gcc7-opt/setup.sh\n",
    "export PATH=`pwd`/.local/bin:$PATH\n",
    "export PYTHONPATH=`pwd`/.local/lib/python3.6/site-packages:$PYTHONPATH\n",
    "\n",
    "export X509_USER_PROXY=`pwd`/%s\n",
    "mkdir -p ./htex_Local\n",
    "'''%(x509_proxy)\n",
    "\n",
    "twoGB = 2048\n",
    "nproc = 4\n",
    "\n",
    "condor_cfg = '''\n",
    "transfer_output_files = htex_Local\n",
    "RequestMemory = %d\n",
    "RequestCpus = %d\n",
    "'''%(twoGB*nproc,nproc)\n",
    "\n",
    "xfer_files = ['/afs/hep.wisc.edu/home/lgray/.local','/tmp/%s'%(x509_proxy)]\n",
    "\n",
    "#envs={'PYTHONPATH':'/afs/hep.wisc.edu/home/lgray/.local/lib/python3.6/site-packages:%s'%os.environ['PYTHONPATH'],\n",
    "#      'X509_USER_PROXY':'./%s'%x509_proxy,\n",
    "#      'PATH':'/afs/hep.wisc.edu/home/lgray/.local/bin:%s'%os.environ['PATH']}\n",
    "\n",
    "local_htex = Config(\n",
    "    executors=[\n",
    "        HighThroughputExecutor(\n",
    "            label=\"htex_Local\",\n",
    "            address=address_by_hostname(),\n",
    "            prefetch_capacity=0,\n",
    "            worker_debug=True,\n",
    "            cores_per_worker=1,\n",
    "            max_workers=nproc,\n",
    "            #max_blocks=200,\n",
    "            #workers_per_node=1,\n",
    "            worker_logdir_root='./',\n",
    "            provider=CondorProvider(\n",
    "                channel=LocalChannel(),\n",
    "                init_blocks=16,\n",
    "                max_blocks=200,\n",
    "                nodes_per_block=1,\n",
    "                worker_init = wrk_init,                \n",
    "                transfer_input_files=xfer_files,\n",
    "                scheduler_options=condor_cfg\n",
    "            ),\n",
    "        )\n",
    "    ],\n",
    "    #strategy=None,\n",
    ")\n",
    "\n",
    "#parsl.set_stream_logger() # <-- log everything to stdout\n",
    "\n",
    "print(parsl.__version__)\n",
    "print(parsl.load(local_htex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@python_app\n",
    "def hello ():\n",
    "    say_hello = 'Hello World!'\n",
    "    print(say_hello)\n",
    "    return say_hello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hello().result())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lz4.frame as lz4f\n",
    "import cloudpickle as cpkl\n",
    "import pprint\n",
    "import numpy as np\n",
    "from fnal_column_analysis_tools import hist, processor\n",
    "\n",
    "class ParslTestProcessor(processor.ProcessorABC):\n",
    "    def __init__(self, debug=False):\n",
    "        self._debug = debug\n",
    "\n",
    "        dataset = hist.Cat(\"dataset\", \"Primary dataset\")\n",
    "        gencat = hist.Bin(\"AK8Puppijet0_isHadronicV\", \"Matched\", 4, 0., 4)\n",
    "        jetpt = hist.Bin(\"AK8Puppijet0_pt\", \"Jet $p_T$\", [450, 500, 550, 600, 675, 800, 1000])\n",
    "        jetpt_coarse = hist.Bin(\"AK8Puppijet0_pt\", \"Jet $p_T$\", [450, 2000])\n",
    "        jetmass = hist.Bin(\"AK8Puppijet0_msd\", \"Jet $m_{sd}$\", 23, 40, 201)\n",
    "        jetmass_coarse = hist.Bin(\"AK8Puppijet0_msd\", \"Jet $m_{sd}$\", [40, 100, 140, 200])\n",
    "        jetrho = hist.Bin(\"jetrho\", r\"Jet $\\rho$\", 13, -6, -2.1)\n",
    "        doubleb = hist.Bin(\"AK8Puppijet0_deepdoubleb\", \"Double-b\", 20, 0., 1)\n",
    "        doublec = hist.Bin(\"AK8Puppijet0_deepdoublec\", \"Double-c\", 20, 0., 1.)\n",
    "        doublecvb = hist.Bin(\"AK8Puppijet0_deepdoublecvb\", \"Double-cvb\", 20, 0., 1.)\n",
    "        doubleb_coarse = [1., 0.93, 0.92, 0.89, 0.85, 0.7,0.]\n",
    "        doubleb_coarse = hist.Bin(\"AK8Puppijet0_deepdoubleb\", \"Double-b\", doubleb_coarse[::-1])\n",
    "        doublec_coarse = [0.87, 0.84, 0.83, 0.79, 0.69, 0.58,0.]\n",
    "        doublec_coarse = hist.Bin(\"AK8Puppijet0_deepdoublec\", \"Double-c\", doublec_coarse[::-1])\n",
    "        doublecvb_coarse = [0.93, 0.91, 0.86, 0.76, 0.6, 0.17, 0.12,0.]\n",
    "        doublecvb_coarse = hist.Bin(\"AK8Puppijet0_deepdoublecvb\", \"Double-cvb\", doublecvb_coarse[::-1])\n",
    "        n2ddt = hist.Bin(\"AK8Puppijet0_N2sdb1_ddt\", \"N2 DDT\", 20, -0.25, 0.25)\n",
    "        n2ddt_coarse = hist.Bin(\"AK8Puppijet0_N2sdb1_ddt\", \"N2 DDT\", [-0.1, 0.])\n",
    "\n",
    "        hists = processor.dict_accumulator()\n",
    "        hist.Hist.DEFAULT_DTYPE = 'f'  # save some space by keeping float bin counts instead of double\n",
    "        \n",
    "        hists['tagtensor_def'] = hist.Hist(\"Events\", dataset,  \n",
    "                                           jetpt, jetmass, \n",
    "                                           doubleb_coarse, doublec_coarse, \n",
    "                                           doublecvb_coarse)\n",
    "        \n",
    "        self._accumulator = hists\n",
    "\n",
    "    @property\n",
    "    def accumulator(self):\n",
    "        return self._accumulator\n",
    "    \n",
    "    def process(self, df):\n",
    "        dataset = df['dataset']\n",
    "                \n",
    "        AK8Puppijet_pt = df['AK8Puppi.pt']\n",
    "        AK8Puppijet_msd = df['AddAK8Puppi.mass_sd0']\n",
    "        AK8Puppijet_deepdoubleb = df['AddAK8Puppi.deepdoubleb']\n",
    "        AK8Puppijet_deepdoublec = df['AddAK8Puppi.deepdoublec']\n",
    "        AK8Puppijet_deepdoublecvb = df['AddAK8Puppi.deepdoublecvb']\n",
    "                \n",
    "        leading_jet = AK8Puppijet_pt.argmax()\n",
    "        AK8Puppijet0_pt = AK8Puppijet_pt[leading_jet].flatten()\n",
    "        AK8Puppijet0_msd = AK8Puppijet_msd[leading_jet].flatten()\n",
    "        AK8Puppijet0_deepdoubleb = AK8Puppijet_deepdoubleb[leading_jet].flatten()\n",
    "        AK8Puppijet0_deepdoublec = AK8Puppijet_deepdoublec[leading_jet].flatten()\n",
    "        AK8Puppijet0_deepdoublecvb = AK8Puppijet_deepdoublecvb[leading_jet].flatten()\n",
    "        \n",
    "        hout = self.accumulator.identity()\n",
    "        hout['tagtensor_def'].fill(dataset=dataset,\n",
    "                                   AK8Puppijet0_pt=AK8Puppijet0_pt,\n",
    "                                   AK8Puppijet0_msd=AK8Puppijet0_msd,\n",
    "                                   AK8Puppijet0_deepdoubleb=AK8Puppijet0_deepdoubleb,\n",
    "                                   AK8Puppijet0_deepdoublec=AK8Puppijet0_deepdoublec,\n",
    "                                   AK8Puppijet0_deepdoublecvb=AK8Puppijet0_deepdoublecvb)\n",
    "        \n",
    "        return hout\n",
    "\n",
    "    def postprocess(self, accumulator):\n",
    "        pass\n",
    "    \n",
    "myprocessor = ParslTestProcessor()\n",
    "myprocessorstr = lz4f.compress(cpkl.dumps(myprocessor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import concurrent.futures\n",
    "import numpy as np\n",
    "from io import BytesIO\n",
    "import time\n",
    "\n",
    "import random\n",
    "import os.path as path\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "@python_app\n",
    "def open_xrd_file(eosroot,fpath,dataset,myprocessorstr):\n",
    "    import uproot\n",
    "    import time\n",
    "    import random\n",
    "    import cloudpickle as cpkl\n",
    "    import lz4.frame as lz4f\n",
    "    from fnal_column_analysis_tools import processor,hist\n",
    "    myprocessor = cpkl.loads(lz4f.decompress(myprocessorstr))\n",
    "    tic1 = time.time()\n",
    "    hists = myprocessor.accumulator.identity()\n",
    "    numentries = 0\n",
    "    with uproot.open(eosroot+fpath) as rootf:\n",
    "        tree = rootf['Events']\n",
    "        numentries += tree.numentries        \n",
    "        df = processor.LazyDataFrame(tree)\n",
    "        df['dataset'] = dataset\n",
    "        hists += myprocessor.process(df)\n",
    "    toc1 = time.time()\n",
    "    return(hists,numentries,(toc1-tic1))\n",
    "\n",
    "#@python_app\n",
    "def open_fuse_file(fuseroot,fpath):\n",
    "    import time\n",
    "    import numpy as np\n",
    "    tic1 = time.time()\n",
    "    nevent_in_file = None\n",
    "    tic1,toc1 = time.time(),None\n",
    "    with np.load(fuseroot+fpath) as npzfile:\n",
    "        nevents_in_file = npzfile['nevents_in_file']\n",
    "    toc1 = time.time()\n",
    "    return(nevents_in_file,(toc1-tic1))\n",
    "\n",
    "def recurse_dir(xrdfs,rootdir,out):\n",
    "    dirinfo = xrdfs.dirlist(rootdir)\n",
    "    for dirfile in dirinfo[1]['dirlist']:\n",
    "        newdir = path.join(rootdir,dirfile['name'])\n",
    "        if '.root' in newdir:\n",
    "            out.append(newdir)\n",
    "        elif '.log.tar.gz' in newdir:\n",
    "            pass\n",
    "        else:\n",
    "            recurse_dir(xrdfs,newdir,out)\n",
    "            \n",
    "\n",
    "def print_file(root,thefile):\n",
    "    time.sleep(1)\n",
    "    print(root,thefile)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pyxrootd.client\n",
    "\n",
    "fnaleos = \"root://cmseos.fnal.gov/\"\n",
    "fuseroot = \"/eos/uscms\"\n",
    "xrdfs = pyxrootd.client.FileSystem(fnaleos)\n",
    "\n",
    "dataset = 'WJetsToQQ_HT-800toInf_qc19_3j_TuneCP5_13TeV-madgraphMLM-pythia8'\n",
    "\n",
    "testdir = '/store/user/lpcbacon/15/WJetsToQQ_HT-800toInf_qc19_3j_TuneCP5_13TeV_10X/WJetsToQQ_HT-800toInf_qc19_3j_TuneCP5_13TeV-madgraphMLM-pythia8/CRAB3/190125_165530/'\n",
    "outfiles = list()\n",
    "recurse_dir(xrdfs,testdir,outfiles)\n",
    "del xrdfs\n",
    "\n",
    "\n",
    "#with open('rootfiles.txt','w') as f:\n",
    "#    for afile in outfiles:\n",
    "#        f.write(afile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#res = open_fuse_file(fuseroot,outfiles[0]).result()\n",
    "#print('try fuse:',res[0],res[1])\n",
    "tic = time.time()\n",
    "future_to_file = {open_xrd_file(fnaleos, npzfile, dataset, myprocessorstr): npzfile for npzfile in outfiles}\n",
    "time_per_file = 0.0\n",
    "total_events = 0\n",
    "outhists = myprocessor.accumulator.identity()\n",
    "for i,future in enumerate(tqdm(concurrent.futures.as_completed(future_to_file),total=len(future_to_file))):\n",
    "    res = future.result()\n",
    "    time_per_file += res[2]\n",
    "    total_events += res[1]\n",
    "    outhists += res[0]\n",
    "toc = time.time()\n",
    "\n",
    "print('read',len(future_to_file),'files in',toc-tic,'seconds')\n",
    "print(time_per_file/len(future_to_file),'seconds per file and',total_events,'total events')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "process = hist.Cat(\"process\", \"Process\", sorting='placement')\n",
    "process_cats = (\"dataset\",)\n",
    "process_map = OrderedDict()\n",
    "process_map[\"Wqq\"] = (\"WJetsToQQ*\",)\n",
    "process_map[\"Zqq\"] = (\"ZJetsToQQ*\",)\n",
    "process_map[\"Single Top\"] = (\"ST*\")\n",
    "process_map[\"TTbar\"] = (\"TTTo*\",)\n",
    "#process_map[\"QCD\"] = (\"QCD*\",)\n",
    "process_map[\"HToBB (x10)\"] = (\"GluGluHToBB*\",)\n",
    "process_map[\"HToCC (x100)\"] = (\"GluGluHToCC*\",)\n",
    "\n",
    "import pickle, gzip\n",
    "\n",
    "#with gzip.open('gghbb_plots.pkl.gz','wb') as fout:\n",
    "#    pickle.dump(gghbb_hists, fout)\n",
    "plots = outhists['tagtensor_def'].copy()\n",
    "plots = plots.group(process, process_cats, process_map)\n",
    "print(plots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "all_axes = ['AK8Puppijet0_pt','AK8Puppijet0_msd',\n",
    "            'AK8Puppijet0_deepdoubleb','AK8Puppijet0_deepdoublec','AK8Puppijet0_deepdoublecvb']\n",
    "plots_list = ['AK8Puppijet0_pt', 'AK8Puppijet0_msd',\n",
    "              'AK8Puppijet0_deepdoubleb','AK8Puppijet0_deepdoublec']\n",
    "names = []\n",
    "out_plots = []\n",
    "for i in range(2):\n",
    "    for j in range(2):        \n",
    "        sum_over = deepcopy(all_axes)\n",
    "        name = plots_list[i*2+j]\n",
    "        sum_over.remove(name)\n",
    "        out_plots.append(plots.sum(*sum_over))\n",
    "for aplot in out_plots:\n",
    "    print(aplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from cycler import cycler\n",
    "\n",
    "%matplotlib inline\n",
    "from fnal_column_analysis_tools import hist\n",
    "from fnal_column_analysis_tools.hist import plot\n",
    "\n",
    "plt.rcParams.update({'font.size': 14, 'axes.titlesize': 18, 'axes.labelsize': 18, 'xtick.labelsize': 12, 'ytick.labelsize': 12})\n",
    "fig, ax = plt.subplots(2, 2, figsize=(15,15))\n",
    "import matplotlib\n",
    "\n",
    "# http://colorbrewer2.org/#type=qualitative&scheme=Paired&n=6\n",
    "colors = ['#a6cee3','#1f78b4','#b2df8a','#33a02c','#fb9a99','#e31a1c']\n",
    "\n",
    "fill_opts = {'edgecolor': (0,0,0,0.3), 'alpha': 0.8}\n",
    "error_opts = {'label':'Stat. Unc.', 'hatch':'///', 'facecolor':'none', 'edgecolor':(0,0,0,.5), 'linewidth': 0}\n",
    "nostack_fill_opts = {'alpha': 0.2, 'label': '_nolabel_'}\n",
    "data_err_opts = {'linestyle':'none', 'marker': '.', 'markersize': 10., 'color':'k', 'elinewidth': 1, 'emarker': '_'}\n",
    "\n",
    "ilumifb = 1.0\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        ax[i,j].set_prop_cycle(cycler(color=colors))  \n",
    "        plot.plot1d(out_plots[i*2+j], ax=ax[i,j], overlay=\"process\", clear=False, stack=True, line_opts=None, fill_opts=fill_opts, error_opts=error_opts)        \n",
    "        #ret = plot.plot1d(ax[0,0], data_plot, \"m_J\", error_opts=data_err_opts)\n",
    "        ax[i,j].autoscale(axis='x', tight=True)\n",
    "        ax[i,j].set_ylim(0, None)\n",
    "        leg = ax[i,j].legend()\n",
    "        coffee = plt.text(0., 1., u\"☕\", fontsize=28, horizontalalignment='left', verticalalignment='bottom', transform=ax[i,j].transAxes)\n",
    "        lumi = plt.text(1., 1., r\"%.1f fb$^{-1}$ (13 TeV)\"%ilumifb, fontsize=16, horizontalalignment='right', verticalalignment='bottom', transform=ax[i,j].transAxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsl.dfk().cleanup()\n",
    "parsl.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x509_proxy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
